{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lightonml.projections.sklearn import OPUMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_x1_x2(n):\n",
    "    x1 = np.random.choice([0,1], size=n**2, p=[0.75,0.25]) # binary signal\n",
    "    x2 = np.random.choice([0,1], size=n**2, p=[0.5,0.5]) # binary signal\n",
    "    \n",
    "    x2[x1>0] = 0 # this is so that after addition, x1+x2 is stil binary\n",
    "    \n",
    "    xs = np.vstack((x1,x2, x1+x2)) # add x1+x2\n",
    "    \n",
    "    return xs\n",
    "    \n",
    "def make_anchors(n, xs, number_of_anchors):\n",
    "    anchors = np.zeros([number_of_anchors, n**2]) # store the anchors here\n",
    "    \n",
    "    anchor_p = [0.8,0.2]\n",
    "    anchors[0] = np.random.choice([0,1], size=n**2, p=anchor_p) + xs[2] # first anchor is random binary\n",
    "    \n",
    "    for i in range(1, number_of_anchors):\n",
    "        # add random binary to previous anchor to get next anchor\n",
    "        anchors[i] = np.random.choice([0,1], size=n**2, p=anchor_p) + anchors[i-1]\n",
    "\n",
    "    anchors[anchors>0] = 1 # input cannot be above 1\n",
    "    anchors = anchors[::-1] # reverse the order for later convenience when interfering with signal\n",
    "    \n",
    "    return anchors\n",
    "\n",
    "def interfere_with_anchors(n, x, anchors):\n",
    "    interfered = anchors - x # interfere all anchors with signal\n",
    "    interfered = np.vstack((interfered, x)) # x with zero (zero is less than x so subtract the other way)\n",
    "    \n",
    "    anchors = np.vstack((anchors, np.zeros(n**2))) # zero is an anchor too\n",
    "    \n",
    "    for i in range(anchors.shape[0]-1):\n",
    "        # subtract all anchors from each other\n",
    "        diffs = anchors[i] - anchors[1+i:]\n",
    "        interfered = np.vstack((interfered, diffs))\n",
    "    \n",
    "    return interfered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "number_of_anchors = 15\n",
    "num_of_rows_in_A = 100\n",
    "\n",
    "xs = make_x1_x2(image_size)\n",
    "anchors = make_anchors(image_size, xs, number_of_anchors)\n",
    "\n",
    "x1_inter = interfere_with_anchors(image_size, xs[0], anchors)\n",
    "x2_inter = interfere_with_anchors(image_size, xs[1], anchors)\n",
    "x1_plus_x2_inter = interfere_with_anchors(image_size, xs[2], anchors)\n",
    "\n",
    "# we can put everything into the OPU in one go by concatenating\n",
    "opu_input = np.vstack((x1_inter, x2_inter, x1_plus_x2_inter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OPU_measurements(opu_input, num_rand_proj):\n",
    "    mapping = OPUMap(n_components=num_rand_proj, verbose_level=2)\n",
    "    mapping.opu.device.exposure_us = 400 # exposure needs to be chosen so that there is no saturation.\n",
    "    y = mapping.transform(opu_input.astype('uint8'))\n",
    "    print ('Max value:', np.max(y))\n",
    "    print ('Min value: ', np.min(y))\n",
    "    \n",
    "    return y\n",
    "\n",
    "# get the OPU measurements\n",
    "y_quant = get_OPU_measurements(opu_input, num_of_rows_in_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_D_ensembles(y, number_of_anchors):\n",
    "    # populates the distance matrices for all rows\n",
    "    \n",
    "    num_elements = int((number_of_anchors+2)* (number_of_anchors+1) * 0.5)\n",
    "    \n",
    "    trials = y.shape[1]\n",
    "    dim = number_of_anchors+2\n",
    "    all_D_oracles_x1 = np.zeros([trials, dim, dim])\n",
    "    all_D_oracles_x2 = np.zeros([trials, dim, dim])\n",
    "    all_D_oracles_x1_plus_x2 = np.zeros([trials, dim, dim])\n",
    "    \n",
    "    ind = np.triu_indices(all_D_oracles_x1[0].shape[0], k=1)\n",
    "    for i in range(trials):\n",
    "        # for x1\n",
    "        data = y[0:num_elements,i]\n",
    "        all_D_oracles_x1[i][ind] = data\n",
    "        all_D_oracles_x1[i] += all_D_oracles_x1[i].T\n",
    "        \n",
    "        # for x2\n",
    "        data = y[num_elements: 2*num_elements,i]\n",
    "        all_D_oracles_x2[i][ind] = data\n",
    "        all_D_oracles_x2[i] += all_D_oracles_x2[i].T\n",
    "        \n",
    "        # for x3\n",
    "        data = y[2*num_elements: 3*num_elements,i]\n",
    "        all_D_oracles_x1_plus_x2[i][ind] = data\n",
    "        all_D_oracles_x1_plus_x2[i] += all_D_oracles_x1_plus_x2[i].T\n",
    "        \n",
    "    return all_D_oracles_x1, all_D_oracles_x2, all_D_oracles_x1_plus_x2\n",
    "\n",
    "def do_MDS(D, number_of_anchors):\n",
    "    # does MDS\n",
    "    \n",
    "    m = number_of_anchors\n",
    "    J = np.eye(m + 2) - 1. / (m + 2) * np.ones((m + 2, m + 2))\n",
    "    G = -1/2 * np.dot(J, D).dot(J)\n",
    "    U, s, VT = np.linalg.svd(G)\n",
    "    Z_est_R2 = np.dot(np.diag(np.sqrt(s[:2])), VT[:2, :])\n",
    "    Z_est_cpx = Z_est_R2[0, :] + 1j*Z_est_R2[1, :]\n",
    "    \n",
    "    # translate the origin back at (0, 0)\n",
    "    Z_est_cpx -= Z_est_cpx[m + 1]\n",
    "    \n",
    "    return Z_est_cpx\n",
    "\n",
    "def ortho_procrustes(fixed, modify):\n",
    "    # does the Procrustes analysis following procedure Dokmanic et al. in references\n",
    "    # and https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem\n",
    "    # assumes that the points to align are in column with index 1 onwards.\n",
    "    # we want to align modify with fixed\n",
    "    \n",
    "    fixed = np.vstack ((np.real(fixed[1:]), np.imag(fixed[1:])))\n",
    "    modify = np.vstack ((np.real(modify), np.imag(modify)))\n",
    "    original = modify.copy()\n",
    "    modify = modify[:,1:]\n",
    "    fixed_mean = (np.mean(fixed, axis=1)).reshape([-1,1])\n",
    "    fixed -= fixed_mean\n",
    "    modify_mean = (np.mean(modify, axis=1)).reshape([-1,1])\n",
    "    modify -= modify_mean\n",
    "    M = fixed @ modify.T\n",
    "    u, s, vh = np.linalg.svd(M)\n",
    "    R = u @ vh\n",
    "    original = R @ (original - modify_mean @ np.ones([1, original.shape[1]])) + fixed_mean@np.ones([1, original.shape[1]])\n",
    "    return original[0] + 1j*original[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_LXX(X):\n",
    "    # intermediate function for MDS with gradient descent\n",
    "    \n",
    "    e = np.ones([X.shape[1],1])\n",
    "    G = X.T @ X\n",
    "    diag_vec = np.diag(G).reshape([-1,1])\n",
    "    L =  diag_vec @ e.T + e @ diag_vec.T - 2*G\n",
    "    return L\n",
    "    \n",
    "def gradient_descent_X(D, X_0, W):\n",
    "    # does gradient descent on MDS solution\n",
    "    \n",
    "    lr = 0.001\n",
    "\n",
    "    n_iter = 20\n",
    "    \n",
    "    N = X_0.shape[1]\n",
    "    e = np.ones([N,1])\n",
    "    \n",
    "    X = X_0.copy()\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        L = make_LXX(X)\n",
    "        P = D - L\n",
    "        P = W*P\n",
    "        grad = (1/N**2) * (8 * X @ (P - np.diag(np.diag(P @ e)) ))\n",
    "        X -= lr*grad\n",
    "\n",
    "    return X, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# put all the measurements into distance matrices\n",
    "all_D_quant_x1, all_D_quant_x2, all_D_quant_x1_plus_x2 = make_D_ensembles(y_quant, number_of_anchors)\n",
    "    \n",
    "# for storing the results    \n",
    "manual = np.zeros([num_of_rows_in_A, number_of_anchors+1-2]).astype('complex128')\n",
    "direct = np.zeros([num_of_rows_in_A, number_of_anchors+1-2]).astype('complex128')\n",
    "manual_gd = np.zeros([num_of_rows_in_A, number_of_anchors+1-2]).astype('complex128')\n",
    "direct_gd = np.zeros([num_of_rows_in_A, number_of_anchors+1-2]).astype('complex128')\n",
    "\n",
    "floor = np.min(y_quant)\n",
    "\n",
    "for trial in tqdm(range(num_of_rows_in_A)):\n",
    "    for i in range(2,number_of_anchors+1):\n",
    "        # choose a random subset of the anchors\n",
    "        ind = np.random.choice(np.arange(1, number_of_anchors+1), i, replace=False)\n",
    "        ind = np.hstack((ind,0,number_of_anchors+1)) # we need the original signal measurement and origin\n",
    "        ind.sort()\n",
    "\n",
    "        # get the distance matrices\n",
    "        D_quant_x1 = all_D_quant_x1[:,:,ind][trial][ind,:]\n",
    "        D_quant_x2 = all_D_quant_x2[:,:,ind][trial][ind,:]\n",
    "        D_quant_x1_plus_x2 = all_D_quant_x1_plus_x2[:,:,ind][trial][ind,:]\n",
    "        \n",
    "        D_quant_x1[D_quant_x1<=floor] = 0\n",
    "        D_quant_x2[D_quant_x2<=floor] = 0\n",
    "        D_quant_x1_plus_x2[D_quant_x1_plus_x2<=floor] = 0\n",
    "\n",
    "        # recover points via normal MDS\n",
    "        recovered_points_x1 = do_MDS(D_quant_x1, i)\n",
    "        recovered_points_x2 = do_MDS(D_quant_x2, i)\n",
    "        recovered_points_x1_plus_x2 = do_MDS(D_quant_x1_plus_x2, i)\n",
    "        # align x2 anchors with x1 anchors\n",
    "        recovered_points_x2 = ortho_procrustes(recovered_points_x1, recovered_points_x2)\n",
    "        # align x1+x2 anchors with x1 anchors\n",
    "        recovered_points_x1_plus_x2 = ortho_procrustes(recovered_points_x1, recovered_points_x1_plus_x2)\n",
    "\n",
    "        # save results\n",
    "        manual[trial, i-2] = recovered_points_x1[0] + recovered_points_x2[0] # recovered x1+x2\n",
    "        direct[trial, i-2] = recovered_points_x1_plus_x2[0] # measured x1+x2\n",
    "\n",
    "        # grad descent\n",
    "        # get the distance matrices\n",
    "        D_quant_x1 = all_D_quant_x1[:,:,ind][trial][ind,:]\n",
    "        D_quant_x2 = all_D_quant_x2[:,:,ind][trial][ind,:]\n",
    "        D_quant_x1_plus_x2 = all_D_quant_x1_plus_x2[:,:,ind][trial][ind,:]\n",
    "        \n",
    "        # for x1\n",
    "        X_0 = np.vstack((np.real(recovered_points_x1), np.imag(recovered_points_x1))) # get initialization for grad descent\n",
    "        W = (D_quant_x1>floor).astype('float') + np.eye(D_quant_x1.shape[0]) # grad descent mask\n",
    "        X, _ = gradient_descent_X(D_quant_x1, X_0, W) # do gradient descent\n",
    "        recovered_points_x1 = X[0] + 1j*X[1] # convert back to complex points\n",
    "        recovered_points_x1 -= recovered_points_x1[-1] # center\n",
    "\n",
    "        # same as above but for x2\n",
    "        X_0 = np.vstack((np.real(recovered_points_x2), np.imag(recovered_points_x2)))\n",
    "        W = (D_quant_x2>floor).astype('float') + np.eye(D_quant_x2.shape[0])\n",
    "        X, L = gradient_descent_X(D_quant_x2, X_0, W)\n",
    "        recovered_points_x2 = X[0] + 1j*X[1]\n",
    "        recovered_points_x2 -= recovered_points_x2[-1]\n",
    "\n",
    "        # same as above but for x1+x2\n",
    "        X_0 = np.vstack((np.real(recovered_points_x1_plus_x2), np.imag(recovered_points_x1_plus_x2)))\n",
    "        W = (D_quant_x1_plus_x2>floor).astype('float') + np.eye(D_quant_x1_plus_x2.shape[0])\n",
    "        X, L = gradient_descent_X(D_quant_x1_plus_x2, X_0, W)\n",
    "        recovered_points_x1_plus_x2 = X[0] + 1j*X[1]\n",
    "        recovered_points_x1_plus_x2 -= recovered_points_x1_plus_x2[-1]\n",
    "\n",
    "        # align x2 anchors with x1 anchors\n",
    "        recovered_points_x2 = ortho_procrustes(recovered_points_x1, recovered_points_x2)\n",
    "        # align x1+x2 anchors with x1 anchors\n",
    "        recovered_points_x1_plus_x2 = ortho_procrustes(recovered_points_x1, recovered_points_x1_plus_x2)\n",
    "\n",
    "        # save results\n",
    "        manual_gd[trial, i-2] = recovered_points_x1[0] + recovered_points_x2[0]\n",
    "        direct_gd[trial, i-2] = recovered_points_x1_plus_x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prevent dividing from small values which have undue influence\n",
    "mask = (np.abs(direct)>2.5).astype('int')\n",
    "mask_sum = (np.sum(mask, axis=0))\n",
    "\n",
    "# prevent dividing from small values which have undue influence\n",
    "mask_gd = (np.abs(direct_gd)>2.5).astype('int')\n",
    "mask_sum_gd = (np.sum(mask_gd, axis=0))\n",
    "\n",
    "# compute all relative errors\n",
    "rel_errors = 100*(np.abs(manual - direct) / np.abs(direct))\n",
    "rel_errors_gd = 100*(np.abs(manual_gd - direct_gd) / np.abs(direct_gd))\n",
    "\n",
    "# compute average relative error for ones which do not have undue influence\n",
    "rel_errors = np.sum(rel_errors*mask, axis=0) / mask_sum\n",
    "rel_errors_gd = np.sum(rel_errors_gd*mask_gd, axis=0) /mask_sum_gd\n",
    "\n",
    "# plot results\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(5,4))\n",
    "anchors_for_plot = np.arange(2, number_of_anchors+1)\n",
    "plt.plot(anchors_for_plot, rel_errors, label='MDS', linewidth=2.5)\n",
    "plt.plot(anchors_for_plot, rel_errors_gd, label='MDS-GD', color='r', linestyle= (0, (5, 1)), linewidth=2.5)\n",
    "plt.ylabel('Average relative error (%)')\n",
    "plt.xlabel('Number of anchors')\n",
    "plt.xticks(np.arange(min(anchors_for_plot), max(anchors_for_plot)+1, 2.0))\n",
    "plt.grid(which='major')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (LightOn OPU)",
   "language": "python",
   "name": "lighton_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
