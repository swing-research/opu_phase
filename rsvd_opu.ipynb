{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg as lg\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lightonml.projections.sklearn import OPUMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cconj(A):\n",
    "    # simple conjugate transpose\n",
    "    return np.conj(A.T)\n",
    "\n",
    "def do_MDS(D, number_of_anchors):\n",
    "    # does MDS\n",
    "    \n",
    "    m = number_of_anchors\n",
    "    J = np.eye(m + 2) - 1. / (m + 2) * np.ones((m + 2, m + 2))\n",
    "    G = -1/2 * np.dot(J, D).dot(J)\n",
    "    U, s, VT = np.linalg.svd(G)\n",
    "    Z_est_R2 = np.dot(np.diag(np.sqrt(s[:2])), VT[:2, :])\n",
    "    Z_est_cpx = Z_est_R2[0, :] + 1j*Z_est_R2[1, :]\n",
    "    \n",
    "    # translate the origin back at (0, 0)\n",
    "    Z_est_cpx -= Z_est_cpx[m + 1]\n",
    "    \n",
    "    return Z_est_cpx\n",
    "\n",
    "def ortho_procrustes(fixed, modify):\n",
    "    # does the Procrustes analysis following procedure Dokmanic et al. in references\n",
    "    # and https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem\n",
    "    # assumes that the points to align are in column with index 1 onwards.\n",
    "    # we want to align modify with fixed\n",
    "    \n",
    "    fixed = np.vstack ((np.real(fixed[1:]), np.imag(fixed[1:])))\n",
    "    modify = np.vstack ((np.real(modify), np.imag(modify)))\n",
    "    original = modify.copy()\n",
    "    modify = modify[:,1:]\n",
    "    fixed_mean = (np.mean(fixed, axis=1)).reshape([-1,1])\n",
    "    fixed -= fixed_mean\n",
    "    modify_mean = (np.mean(modify, axis=1)).reshape([-1,1])\n",
    "    modify -= modify_mean\n",
    "    M = fixed @ modify.T\n",
    "    u, s, vh = np.linalg.svd(M)\n",
    "    R = u @ vh\n",
    "    original = R @ (original - modify_mean @ np.ones(\n",
    "        [1, original.shape[1]])) + fixed_mean@np.ones([1, original.shape[1]])\n",
    "    return original[0] + 1j*original[1]\n",
    "\n",
    "def make_D_ensembles(y, number_of_anchors):\n",
    "    # populates the distance matrices for all rows\n",
    "    \n",
    "    num_elements = int((number_of_anchors+2)* (number_of_anchors+1) * 0.5)\n",
    "    \n",
    "    trials = y.shape[1]\n",
    "    dim = number_of_anchors+2\n",
    "    all_D_oracles_x = np.zeros([trials, dim, dim])\n",
    "    \n",
    "    ind = np.triu_indices(all_D_oracles_x[0].shape[0], k=1)\n",
    "    for i in range(trials):\n",
    "        data = y[0:num_elements,i]\n",
    "        all_D_oracles_x[i][ind] = data\n",
    "        all_D_oracles_x[i] += all_D_oracles_x[i].T\n",
    "        \n",
    "    return all_D_oracles_x\n",
    "\n",
    "def interfere_with_anchors(n, x, anchors):\n",
    "    interfered = anchors - x # interfere all anchors with signal\n",
    "    interfered = np.vstack((interfered, x)) # x with zero (zero is less than x so subtract the other way)\n",
    "    \n",
    "    anchors = np.vstack((anchors, np.zeros(n))) # zero is an anchor too\n",
    "    \n",
    "    for i in range(anchors.shape[0]-1):\n",
    "        # subtract all anchors from each other\n",
    "        diffs = anchors[i] - anchors[1+i:]\n",
    "        interfered = np.vstack((interfered, diffs))\n",
    "    \n",
    "    return interfered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OPU_measurements(opu_input, num_rand_proj):    \n",
    "    mapping = OPUMap(n_components=num_rand_proj, verbose_level=2)\n",
    "    mapping.opu.device.exposure_us = 400 # exposure needs to be chosen so that there is no saturation.\n",
    "    y = mapping.transform(opu_input.astype('uint8'))\n",
    "    print (y.shape)\n",
    "    print (np.max(y))\n",
    "    print (np.min(y))\n",
    "    \n",
    "    return y\n",
    "\n",
    "def make_anchors(X, number_of_anchors):\n",
    "    # combine all rows of matrix\n",
    "    # then start creating anchors which would not be negative when matrix elements are subtracted from it\n",
    "    X_sum = np.sum(X.copy(), axis=0)\n",
    "    X_sum[X_sum>0] = 1\n",
    "    \n",
    "    anchors = np.zeros([number_of_anchors, n**2]) # store the anchors here\n",
    "    \n",
    "    anchor_p = [0.85,0.15]\n",
    "    \n",
    "    anchors[0] = np.random.choice([0,1], size=X.shape[1], p=anchor_p) + X_sum # first anchor is random binary\n",
    "    \n",
    "    for i in range(1, number_of_anchors):\n",
    "        # add random binary to previous anchor to get next anchor\n",
    "        anchors[i] = np.random.choice([0,1], size=X.shape[1], p=anchor_p) + anchors[i-1]\n",
    "\n",
    "    anchors[anchors>0] = 1 # input cannot be above 1\n",
    "    anchors = anchors[::-1] # reverse the order for later convenience when interfering with signal\n",
    "    \n",
    "    return anchors\n",
    "\n",
    "def opu_projection(X, k):\n",
    "    # does random gaussian matrix multiplication using OPU\n",
    "    # recovers measurement phase too\n",
    "    \n",
    "    number_of_anchors = 5\n",
    "    \n",
    "    anchors = make_anchors(X, number_of_anchors)\n",
    "\n",
    "    # add a dummy all-zero signal and intereferes it. Used to localize anchors later\n",
    "    x = np.zeros([1, X.shape[1]])\n",
    "    opu_input = interfere_with_anchors(X.shape[1], x, anchors)\n",
    "    anchors_input_size = opu_input.shape[0]\n",
    "    \n",
    "    # interfere each row of X with the anchors\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        opu_input = np.vstack((opu_input, interfere_with_anchors(X.shape[1], x, anchors)))\n",
    "    \n",
    "    num_of_rows_in_A = k\n",
    "    print('Getting OPU data')\n",
    "    y_quant = get_OPU_measurements(opu_input, num_of_rows_in_A)\n",
    "    print('Got OPU data')\n",
    "    \n",
    "    # localise anchors using dummy signal\n",
    "    anchor_positions = np.zeros([num_of_rows_in_A, number_of_anchors+2]).astype('complex128')\n",
    "    all_D_quant = make_D_ensembles(y_quant[:anchors_input_size], number_of_anchors)\n",
    "    for i in range(num_of_rows_in_A):\n",
    "        anchor_positions[i] = do_MDS(all_D_quant[i], number_of_anchors)\n",
    "        \n",
    "    # localise other points element by element using our algorithm\n",
    "    results = np.ones([X.shape[0], num_of_rows_in_A]).astype('complex128')\n",
    "    for i in range(X.shape[0]):\n",
    "        all_D_quant = make_D_ensembles(y_quant[(i+1)*anchors_input_size:(i+2)*anchors_input_size], number_of_anchors)\n",
    "        for row in range(num_of_rows_in_A):\n",
    "            recovered_points = do_MDS(all_D_quant[row], number_of_anchors)\n",
    "            recovered_points = ortho_procrustes(anchor_positions[row], recovered_points)\n",
    "            results[i, row] = recovered_points[0]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def randsvd(M, k):\n",
    "    # does randomized SVD\n",
    "    \n",
    "    m, n = M.shape\n",
    "    \n",
    "    Y = opu_projection(M, k)\n",
    "    Y = cconj(Y)\n",
    "    \n",
    "    # split complex projection into two so its equivalent to projection with real matrix\n",
    "    Y = np.vstack((np.real(Y), np.imag(Y)))\n",
    "    Y = cconj(Y)\n",
    "    \n",
    "    # remaining steps are Halko's randomized SVD algorithm\n",
    "    Q = lg.orth(Y)\n",
    "    B = (cconj(Q)) @ M\n",
    "    U_tilde, s, Vh = lg.svd(B, full_matrices=False)\n",
    "    U = Q @ U_tilde\n",
    "    return U, s, Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trials():\n",
    "    # vary number of projections and check the error\n",
    "    num_trials = 10 # reduce this for a faster result\n",
    "    ks = 10\n",
    "    \n",
    "    errors = np.zeros([ks, num_trials])\n",
    "    \n",
    "    for k in tqdm(range(1,ks+1)):\n",
    "        for trial in range(num_trials):\n",
    "    \n",
    "            m = 10\n",
    "            n = 10000\n",
    "            M = np.random.choice([0,1], size=[m, n], p=[0.8,0.2])\n",
    "            U, s, Vh = randsvd(M, k=k) # SVD of M\n",
    "            error = lg.norm(M - U @ np.diag(s) @ Vh) / M.size\n",
    "            errors[k-1, trial] = error\n",
    "    \n",
    "    return M, np.real(U @ np.diag(s) @ Vh), errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B, B_rec, errors_ar = trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.mean(errors_ar, axis=1)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(4,3.5))\n",
    "x_axis = np.linspace(1,10, num=10)\n",
    "plt.plot(x_axis, errors, linewidth=2.5)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Average error per entry')\n",
    "plt.xlabel('Number of projections')\n",
    "plt.xticks(np.arange(min(x_axis), max(x_axis)+1, 2.0)+1)\n",
    "plt.grid(which='major')\n",
    "plt.tight_layout()\n",
    "plt.savefig('svd_OPU_recon_error.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightonml.datasets import MNIST\n",
    "from lightonml.encoding.base import BinaryThresholdEncoder\n",
    "\n",
    "def mnist_matrix():\n",
    "    # make a matrix of flattened MNIST images\n",
    "    \n",
    "    # load data\n",
    "    (_, _), (X, _) = MNIST()\n",
    "    # encode data\n",
    "    encoder = BinaryThresholdEncoder()\n",
    "    X_encoded = encoder.transform(X)\n",
    "    \n",
    "    return X_encoded[:500].reshape([500,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized SVD on MNIST matrix\n",
    "M = mnist_matrix()\n",
    "U, s, Vh = randsvd(M, k=np.min(M.shape))\n",
    "error = lg.norm(M - U @ np.diag(s) @ Vh) / M.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True SVD for comparison\n",
    "U_true, s_true, Vh_true = np.linalg.svd(M, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# view results\n",
    "\n",
    "n_svecs = 7\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.figure(figsize=(8.2, 2.75));\n",
    "for i in range(n_svecs):\n",
    "    fig = plt.subplot(2,n_svecs, 1+i)\n",
    "    phase = (Vh[i, 100]/ Vh_true[i, 100]) # rotation of system may be required\n",
    "    img = np.real(np.conj(phase)*Vh[i]).reshape([28,28])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    fig = plt.subplot(2,n_svecs, n_svecs + 1+i)\n",
    "    img_true = (Vh_true[i]).reshape([28,28])\n",
    "    plt.imshow(img_true, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    rel_error = 100*np.linalg.norm(img-img_true) / np.linalg.norm(img_true)\n",
    "    plt.title('{:.2e}'.format(rel_error), y=-0.35, fontsize=12)\n",
    "\n",
    "plt.suptitle('Leading right singular vectors')\n",
    "plt.figtext(0.0125,0.78,'OPU', size=13, ha='center', rotation='vertical')\n",
    "plt.figtext(0.0125,0.39,'Python', size=13, ha='center', rotation='vertical')\n",
    "plt.figtext(0.5,0,'Relative error', size=12, ha='center')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (LightOn OPU)",
   "language": "python",
   "name": "lighton_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
